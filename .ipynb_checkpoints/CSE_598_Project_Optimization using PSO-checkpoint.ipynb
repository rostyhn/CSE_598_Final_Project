{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Qs05wnIo4NsV"
   },
   "outputs": [],
   "source": [
    "using Flux\n",
    "using MLDatasets\n",
    "using Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fciKXfaQ4NsZ"
   },
   "outputs": [],
   "source": [
    "train_x, train_y = CIFAR10.traindata(Float32, 1:10000)\n",
    "test_x, test_y = CIFAR10.testdata(Float32, 1:10000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZjwdLawu4Nsa",
    "outputId": "97ce3241-cc46-4663-9ef2-559c0d74dd46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of each image: (32, 32, 3, 10000)\n",
      "Label of 50th training datapoint: 0\n"
     ]
    }
   ],
   "source": [
    "println(\"Size of each image: \", size(train_x))\n",
    "println(\"Label of 50th training datapoint: \", train_y[50])\n",
    "# So here we can see that each training point is a 3D array - a 32x32 image with 3 color channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XKn7OEQE4Nsb",
    "outputId": "e617b529-e3d9-4562-9549-a9725a8109bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "# Since this is a multi-class classification problem, we can use one hot encoding, just like the MNIST dataset.\n",
    "# There's 10 classes just like mnist, so we encode from 0 to 9\n",
    "\n",
    "train_y, test_y = Flux.onehotbatch(train_y, 0:9), Flux.onehotbatch(test_y, 0:9)\n",
    "nclasses = length(train_y[:,1])\n",
    "println(\"number of classes: \", nclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cibc0mO44Nsd",
    "outputId": "d2d3e955-ecd2-4b5c-bb38-8a25e4693f74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Conv((3, 3), 3 => 32, relu, pad=1),   \u001b[90m# 896 parameters\u001b[39m\n",
       "  Conv((3, 3), 32 => 32, relu, pad=1),  \u001b[90m# 9_248 parameters\u001b[39m\n",
       "  MaxPool((2, 2)),\n",
       "  Dropout(0.2),\n",
       "  Conv((3, 3), 32 => 64, relu, pad=1),  \u001b[90m# 18_496 parameters\u001b[39m\n",
       "  Conv((3, 3), 64 => 64, relu, pad=1),  \u001b[90m# 36_928 parameters\u001b[39m\n",
       "  MaxPool((2, 2)),\n",
       "  Dropout(0.2),\n",
       "  Conv((3, 3), 64 => 128, relu, pad=1),  \u001b[90m# 73_856 parameters\u001b[39m\n",
       "  Conv((3, 3), 128 => 256, relu, pad=1),  \u001b[90m# 295_168 parameters\u001b[39m\n",
       "  MaxPool((2, 2)),\n",
       "  Dropout(0.2),\n",
       "  Flux.flatten,\n",
       "  Dense(4096, 128, relu),               \u001b[90m# 524_416 parameters\u001b[39m\n",
       "  Dropout(0.2),\n",
       "  Dense(128, 10),                       \u001b[90m# 1_290 parameters\u001b[39m\n",
       "  NNlib.softmax,\n",
       ")\u001b[90m                   # Total: 16 arrays, \u001b[39m960_298 parameters, 3.666 MiB."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 VGG Block\n",
    "model_VGG3 = Chain(\n",
    "              Conv((3,3), 3=>32, relu, pad=SamePad()),\n",
    "              Conv((3,3), 32=>32, relu, pad=SamePad()),\n",
    "              MaxPool((2,2)),\n",
    "              Dropout(0.2),\n",
    "              Conv((3,3), 32=>64, relu, pad=SamePad()),\n",
    "              Conv((3,3), 64=>64, relu, pad=SamePad()),\n",
    "              MaxPool((2,2)),\n",
    "              Dropout(0.2),\n",
    "              Conv((3,3), 64=>128, relu, pad=SamePad()),\n",
    "              Conv((3,3), 128=>256, relu, pad=SamePad()),\n",
    "              MaxPool((2,2)),\n",
    "              Dropout(0.2),\n",
    "              Flux.flatten,\n",
    "              Dense(4096,128,relu),\n",
    "              Dropout(0.2),\n",
    "              Dense(128,10),\n",
    "              softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zfPP93qo4Nsd",
    "outputId": "703629a5-3e9b-48cd-bfa3-0789a25f0878"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_and_accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss_and_accuracy(udata, wdata, model)\n",
    "\n",
    "    ndata = size(udata,4)\n",
    "\n",
    "    ŵ = model(udata)\n",
    "    loss = Flux.crossentropy(ŵ, wdata; agg=sum)\n",
    "    accuracy = sum(Flux.onecold(ŵ) .== Flux.onecold(wdata)) / ndata\n",
    "    return loss, accuracy\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qMPMOsv44Nse"
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_loader = Flux.Data.DataLoader((train_x, train_y), batchsize=batch_size, shuffle=true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "EK3iUdGA4Nsf",
    "outputId": "1b3c262f-a5c9-4286-da32-a226543bb0c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train(model,train_loader,train_x,train_y,test_x,test_y,model_name)\n",
    "    train_losses = []\n",
    "    train_accuracy = []\n",
    "    test_losses = []\n",
    "    test_accuracy = []\n",
    "    opt = ADAM(0.001)\n",
    "    K = 10\n",
    "    for k in 1:K\n",
    "        for (u, w) in train_loader\n",
    "            gs = gradient(() -> Flux.Losses.crossentropy(model(u), w), Flux.params(model)) # compute gradient\n",
    "            Flux.Optimise.update!(opt, Flux.params(model), gs) # update parameters\n",
    "        end\n",
    "        println(\"Epoch $k for $model_name architecture.\")\n",
    "        train_loss, train_acc = loss_and_accuracy(train_x, train_y,  model)\n",
    "\n",
    "        test_loss, test_acc = loss_and_accuracy(test_x, test_y, model)\n",
    "\n",
    "        println(\"  train_loss = $train_loss, train_accuracy = $train_acc\")\n",
    "        println(\"  test_loss = $test_loss, test_accuracy = $test_acc\")\n",
    "        \n",
    "        push!(test_losses, test_loss)\n",
    "        push!(test_accuracy, test_acc)\n",
    "        push!(train_losses, train_loss)\n",
    "        push!(train_accuracy, train_acc)\n",
    "    end\n",
    "    return train_losses, train_accuracy, test_losses, test_accuracy\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to_model (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function to_model(vector)\n",
    "    # while of course we could make something fancy out of this, for now \n",
    "    # let's just have it encode back to our original model\n",
    "    # if we were building a library or something we'd store more information about the\n",
    "    # original model to not have to rebuild it like this\n",
    "    return Chain(\n",
    "              Conv((3,3), 3=>32, relu, pad=SamePad(), weight=reshape(vector[1:864],(3,3,3,32)), bias=vector[865:896]),# 896 - 32 bias 864\n",
    "              Conv((3,3), 32=>32, relu, pad=SamePad(),weight=reshape(vector[897:10112],(3,3,32,32)), bias=vector[10112:10143]),# 9248 - 32 bias 9216\n",
    "              MaxPool((2,2)),\n",
    "              Dropout(0.2),\n",
    "              Conv((3,3), 32=>64, relu, pad=SamePad(), weight=reshape(vector[10144:28575], (3,3,32,64)), bias=vector[28575:28638]), # 18496 - 64 = 18432 \n",
    "              Conv((3,3), 64=>64, relu, pad=SamePad(), weight=reshape(vector[28639:65502], (3,3,64,64)), bias=vector[65503:65566]), # 36928 - 64 = 36864\n",
    "              MaxPool((2,2)),\n",
    "              Dropout(0.2),\n",
    "              Conv((3,3), 64=>128, relu, pad=SamePad(),weight=reshape(vector[65568:139295], (3,3,64,128)), bias=vector[139296:139423]), # 73856 - 128 = 73728\n",
    "              Conv((3,3), 128=>256, relu, pad=SamePad(),weight=reshape(vector[139424:434335], (3,3,128,256)), bias=vector[434336:434591]), # 295168 - 256 = 294912\n",
    "              MaxPool((2,2)),\n",
    "              Dropout(0.2),\n",
    "              Flux.flatten,\n",
    "              Dense(reshape(vector[434592:958879],(128,4096)),vector[958880:959007],relu), # 524416 - 128 bias = 524288\n",
    "              Dropout(0.2),\n",
    "              Dense(reshape(vector[959008:960287], (10,128)),vector[960288:960297],relu)) # 1290 - 10 bias = 1280\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Particle \n",
    "    position::Vector{Float32}\n",
    "    best_position::Vector{Float32}\n",
    "    best_accuracy::Float32\n",
    "    velocity::Vector{Float32}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_PSO (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train_PSO(model,train_loader,train_x,train_y,test_x,test_y, numparticles, ω, c1,c2)\n",
    "    train_losses = []\n",
    "    train_accuracy = []\n",
    "    test_losses = []\n",
    "    test_accuracy = []\n",
    "    particles = []\n",
    "    best_loss, best_accuracy = loss_and_accuracy(train_x, train_y,  model)\n",
    "    \n",
    "    params = Flux.params(model)\n",
    "    params_flattened = []\n",
    "    \n",
    "    for p in params\n",
    "        flattened = flatten(p)\n",
    "        final = reshape(flattened, (1, size(flattened, 1) * size(flattened,2)))\n",
    "        append!(params_flattened, final)\n",
    "    end\n",
    "    \n",
    "    swarm_best_position = params_flattened\n",
    "    d = size(params_flattened)\n",
    "    \n",
    "    #init particles\n",
    "    for n in 1:numparticles\n",
    "        push!(particles, Particle(params_flattened,params_flattened,best_accuracy,rand(Float32,size(params_flattened))))\n",
    "    end\n",
    "\n",
    "    println(\"Initalized particles!\")\n",
    "    \n",
    "    for k in 1:3\n",
    "        for (u, w) in train_loader\n",
    "            for p in particles\n",
    "                # vector math for additional speed boost\n",
    "                # ω - inertia weight, how much the previous velocity impacts the current position\n",
    "                # c1 - how much the particle pays attention to its own best position\n",
    "                # c2 - how much the particle pays attention to the swarm's best position\n",
    "                p.velocity = (ω .* p.velocity) .+\n",
    "                (rand((-1.0,1.0),d) * c1 .* (p.best_position .- p.position)) .+\n",
    "                (rand((-1.0,1.0),d) * c2 .* (swarm_best_position .- p.position))\n",
    "                # need to make sure that these values are always between -1.0 and 1\n",
    "                # clamp. broadcasts to entire vector\n",
    "                p.position = clamp.(p.position .+ p.velocity,0.0,1.0)\n",
    "            \n",
    "                moved_model = to_model(p.position)\n",
    "                this_loss, this_acc = loss_and_accuracy(train_x,train_y, moved_model)\n",
    "                \n",
    "                if p.best_accuracy < this_acc\n",
    "                    p.best_accuracy = this_acc\n",
    "                    p.best_position = p.position\n",
    "                end\n",
    "                \n",
    "                if best_accuracy < this_acc\n",
    "                    best_accuracy = this_acc\n",
    "                    swarm_best_position = p.position\n",
    "                    model = moved_model\n",
    "                    println(\"New accuracy: $this_acc\")\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "\n",
    "        train_loss, train_acc = loss_and_accuracy(train_x, train_y,  model)\n",
    "        test_loss, test_acc = loss_and_accuracy(test_x, test_y, model)\n",
    "\n",
    "        println(\"  train_loss = $train_loss, train_accuracy = $train_acc\")\n",
    "        println(\"  test_loss = $test_loss, test_accuracy = $test_acc\")\n",
    "        \n",
    "        push!(test_losses, test_loss)\n",
    "        push!(test_accuracy, test_acc)\n",
    "        push!(train_losses, train_loss)\n",
    "        push!(train_accuracy, train_acc)\n",
    "    end\n",
    "    return train_losses, train_accuracy, test_losses, test_accuracy, model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: model_VGG3 not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: model_VGG3 not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[15]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "vgg3_train_loss, \n",
    "vgg3_train_accuracy, \n",
    "vgg3_test_loss, \n",
    "vgg3_test_accuracy,trained_model = train_PSO(model_VGG3, train_loader, train_x, train_y,test_x, test_y, 10, 0.5, 0.3, 0.4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ixnHnYkc4Nsg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 for VGG3 architecture.\n",
      "  train_loss = 20367.602, train_accuracy = 0.2582\n",
      "  test_loss = 20450.266, test_accuracy = 0.2564\n",
      "Epoch 2 for VGG3 architecture.\n",
      "  train_loss = 18215.17, train_accuracy = 0.314\n",
      "  test_loss = 18309.78, test_accuracy = 0.3111\n",
      "Epoch 3 for VGG3 architecture.\n",
      "  train_loss = 15890.85, train_accuracy = 0.4238\n",
      "  test_loss = 16036.762, test_accuracy = 0.4183\n",
      "Epoch 4 for VGG3 architecture.\n",
      "  train_loss = 15093.409, train_accuracy = 0.439\n",
      "  test_loss = 15484.565, test_accuracy = 0.4214\n",
      "Epoch 5 for VGG3 architecture.\n",
      "  train_loss = 14860.048, train_accuracy = 0.4577\n",
      "  test_loss = 15272.053, test_accuracy = 0.4421\n",
      "Epoch 6 for VGG3 architecture.\n",
      "  train_loss = 13369.493, train_accuracy = 0.5172\n",
      "  test_loss = 14084.222, test_accuracy = 0.4905\n",
      "Epoch 7 for VGG3 architecture.\n",
      "  train_loss = 12656.422, train_accuracy = 0.5392\n",
      "  test_loss = 13559.54, test_accuracy = 0.503\n",
      "Epoch 8 for VGG3 architecture.\n",
      "  train_loss = 11996.201, train_accuracy = 0.5623\n",
      "  test_loss = 13269.479, test_accuracy = 0.5226\n",
      "Epoch 9 for VGG3 architecture.\n",
      "  train_loss = 11895.495, train_accuracy = 0.5622\n",
      "  test_loss = 13340.402, test_accuracy = 0.5163\n",
      "Epoch 10 for VGG3 architecture.\n",
      "  train_loss = 10204.842, train_accuracy = 0.6361\n",
      "  test_loss = 12019.762, test_accuracy = 0.5608\n"
     ]
    }
   ],
   "source": [
    "vgg3_train_loss, \n",
    "vgg3_train_accuracy, \n",
    "vgg3_test_loss, \n",
    "vgg3_test_accuracy = train(model_VGG3,train_loader,train_x, train_y,test_x, test_y, \"VGG3\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip970\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip970)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip971\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip970)\" d=\"\n",
       "M231.181 1486.45 L2352.76 1486.45 L2352.76 123.472 L231.181 123.472  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip972\">\n",
       "    <rect x=\"231\" y=\"123\" width=\"2123\" height=\"1364\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip972)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  291.226,1486.45 291.226,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip972)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  791.597,1486.45 791.597,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip972)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1291.97,1486.45 1291.97,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip972)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1792.34,1486.45 1792.34,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip972)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2292.71,1486.45 2292.71,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  231.181,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  291.226,1486.45 291.226,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  791.597,1486.45 791.597,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1291.97,1486.45 1291.97,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1792.34,1486.45 1792.34,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2292.71,1486.45 2292.71,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip970)\" d=\"M268.61 1515.64 Q264.999 1515.64 263.17 1519.2 Q261.365 1522.75 261.365 1529.87 Q261.365 1536.98 263.17 1540.55 Q264.999 1544.09 268.61 1544.09 Q272.244 1544.09 274.05 1540.55 Q275.879 1536.98 275.879 1529.87 Q275.879 1522.75 274.05 1519.2 Q272.244 1515.64 268.61 1515.64 M268.61 1511.93 Q274.42 1511.93 277.476 1516.54 Q280.554 1521.12 280.554 1529.87 Q280.554 1538.6 277.476 1543.21 Q274.42 1547.79 268.61 1547.79 Q262.8 1547.79 259.721 1543.21 Q256.666 1538.6 256.666 1529.87 Q256.666 1521.12 259.721 1516.54 Q262.8 1511.93 268.61 1511.93 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M288.772 1541.24 L293.656 1541.24 L293.656 1547.12 L288.772 1547.12 L288.772 1541.24 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M313.841 1515.64 Q310.23 1515.64 308.402 1519.2 Q306.596 1522.75 306.596 1529.87 Q306.596 1536.98 308.402 1540.55 Q310.23 1544.09 313.841 1544.09 Q317.476 1544.09 319.281 1540.55 Q321.11 1536.98 321.11 1529.87 Q321.11 1522.75 319.281 1519.2 Q317.476 1515.64 313.841 1515.64 M313.841 1511.93 Q319.652 1511.93 322.707 1516.54 Q325.786 1521.12 325.786 1529.87 Q325.786 1538.6 322.707 1543.21 Q319.652 1547.79 313.841 1547.79 Q308.031 1547.79 304.953 1543.21 Q301.897 1538.6 301.897 1529.87 Q301.897 1521.12 304.953 1516.54 Q308.031 1511.93 313.841 1511.93 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M763.333 1543.18 L779.653 1543.18 L779.653 1547.12 L757.708 1547.12 L757.708 1543.18 Q760.37 1540.43 764.954 1535.8 Q769.56 1531.15 770.741 1529.81 Q772.986 1527.28 773.866 1525.55 Q774.769 1523.79 774.769 1522.1 Q774.769 1519.34 772.824 1517.61 Q770.903 1515.87 767.801 1515.87 Q765.602 1515.87 763.148 1516.63 Q760.718 1517.4 757.94 1518.95 L757.94 1514.23 Q760.764 1513.09 763.218 1512.51 Q765.671 1511.93 767.708 1511.93 Q773.079 1511.93 776.273 1514.62 Q779.468 1517.31 779.468 1521.8 Q779.468 1523.93 778.657 1525.85 Q777.87 1527.74 775.764 1530.34 Q775.185 1531.01 772.083 1534.23 Q768.982 1537.42 763.333 1543.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M789.468 1541.24 L794.352 1541.24 L794.352 1547.12 L789.468 1547.12 L789.468 1541.24 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M804.583 1512.56 L822.94 1512.56 L822.94 1516.5 L808.866 1516.5 L808.866 1524.97 Q809.884 1524.62 810.903 1524.46 Q811.921 1524.27 812.94 1524.27 Q818.727 1524.27 822.106 1527.44 Q825.486 1530.62 825.486 1536.03 Q825.486 1541.61 822.014 1544.71 Q818.541 1547.79 812.222 1547.79 Q810.046 1547.79 807.778 1547.42 Q805.532 1547.05 803.125 1546.31 L803.125 1541.61 Q805.208 1542.74 807.43 1543.3 Q809.653 1543.86 812.129 1543.86 Q816.134 1543.86 818.472 1541.75 Q820.81 1539.64 820.81 1536.03 Q820.81 1532.42 818.472 1530.31 Q816.134 1528.21 812.129 1528.21 Q810.254 1528.21 808.379 1528.62 Q806.528 1529.04 804.583 1529.92 L804.583 1512.56 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1259.13 1512.56 L1277.49 1512.56 L1277.49 1516.5 L1263.42 1516.5 L1263.42 1524.97 Q1264.43 1524.62 1265.45 1524.46 Q1266.47 1524.27 1267.49 1524.27 Q1273.28 1524.27 1276.66 1527.44 Q1280.04 1530.62 1280.04 1536.03 Q1280.04 1541.61 1276.56 1544.71 Q1273.09 1547.79 1266.77 1547.79 Q1264.6 1547.79 1262.33 1547.42 Q1260.08 1547.05 1257.67 1546.31 L1257.67 1541.61 Q1259.76 1542.74 1261.98 1543.3 Q1264.2 1543.86 1266.68 1543.86 Q1270.68 1543.86 1273.02 1541.75 Q1275.36 1539.64 1275.36 1536.03 Q1275.36 1532.42 1273.02 1530.31 Q1270.68 1528.21 1266.68 1528.21 Q1264.8 1528.21 1262.93 1528.62 Q1261.08 1529.04 1259.13 1529.92 L1259.13 1512.56 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1289.25 1541.24 L1294.13 1541.24 L1294.13 1547.12 L1289.25 1547.12 L1289.25 1541.24 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1314.32 1515.64 Q1310.71 1515.64 1308.88 1519.2 Q1307.07 1522.75 1307.07 1529.87 Q1307.07 1536.98 1308.88 1540.55 Q1310.71 1544.09 1314.32 1544.09 Q1317.95 1544.09 1319.76 1540.55 Q1321.59 1536.98 1321.59 1529.87 Q1321.59 1522.75 1319.76 1519.2 Q1317.95 1515.64 1314.32 1515.64 M1314.32 1511.93 Q1320.13 1511.93 1323.18 1516.54 Q1326.26 1521.12 1326.26 1529.87 Q1326.26 1538.6 1323.18 1543.21 Q1320.13 1547.79 1314.32 1547.79 Q1308.51 1547.79 1305.43 1543.21 Q1302.37 1538.6 1302.37 1529.87 Q1302.37 1521.12 1305.43 1516.54 Q1308.51 1511.93 1314.32 1511.93 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1758.66 1512.56 L1780.88 1512.56 L1780.88 1514.55 L1768.34 1547.12 L1763.45 1547.12 L1775.26 1516.5 L1758.66 1516.5 L1758.66 1512.56 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1790 1541.24 L1794.89 1541.24 L1794.89 1547.12 L1790 1547.12 L1790 1541.24 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1805.12 1512.56 L1823.47 1512.56 L1823.47 1516.5 L1809.4 1516.5 L1809.4 1524.97 Q1810.42 1524.62 1811.44 1524.46 Q1812.46 1524.27 1813.47 1524.27 Q1819.26 1524.27 1822.64 1527.44 Q1826.02 1530.62 1826.02 1536.03 Q1826.02 1541.61 1822.55 1544.71 Q1819.08 1547.79 1812.76 1547.79 Q1810.58 1547.79 1808.31 1547.42 Q1806.07 1547.05 1803.66 1546.31 L1803.66 1541.61 Q1805.74 1542.74 1807.96 1543.3 Q1810.19 1543.86 1812.66 1543.86 Q1816.67 1543.86 1819.01 1541.75 Q1821.34 1539.64 1821.34 1536.03 Q1821.34 1532.42 1819.01 1530.31 Q1816.67 1528.21 1812.66 1528.21 Q1810.79 1528.21 1808.91 1528.62 Q1807.06 1529.04 1805.12 1529.92 L1805.12 1512.56 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M2244.78 1543.18 L2252.42 1543.18 L2252.42 1516.82 L2244.11 1518.49 L2244.11 1514.23 L2252.38 1512.56 L2257.05 1512.56 L2257.05 1543.18 L2264.69 1543.18 L2264.69 1547.12 L2244.78 1547.12 L2244.78 1543.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M2284.13 1515.64 Q2280.52 1515.64 2278.7 1519.2 Q2276.89 1522.75 2276.89 1529.87 Q2276.89 1536.98 2278.7 1540.55 Q2280.52 1544.09 2284.13 1544.09 Q2287.77 1544.09 2289.57 1540.55 Q2291.4 1536.98 2291.4 1529.87 Q2291.4 1522.75 2289.57 1519.2 Q2287.77 1515.64 2284.13 1515.64 M2284.13 1511.93 Q2289.95 1511.93 2293 1516.54 Q2296.08 1521.12 2296.08 1529.87 Q2296.08 1538.6 2293 1543.21 Q2289.95 1547.79 2284.13 1547.79 Q2278.32 1547.79 2275.25 1543.21 Q2272.19 1538.6 2272.19 1529.87 Q2272.19 1521.12 2275.25 1516.54 Q2278.32 1511.93 2284.13 1511.93 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M2304.3 1541.24 L2309.18 1541.24 L2309.18 1547.12 L2304.3 1547.12 L2304.3 1541.24 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M2329.37 1515.64 Q2325.76 1515.64 2323.93 1519.2 Q2322.12 1522.75 2322.12 1529.87 Q2322.12 1536.98 2323.93 1540.55 Q2325.76 1544.09 2329.37 1544.09 Q2333 1544.09 2334.81 1540.55 Q2336.63 1536.98 2336.63 1529.87 Q2336.63 1522.75 2334.81 1519.2 Q2333 1515.64 2329.37 1515.64 M2329.37 1511.93 Q2335.18 1511.93 2338.23 1516.54 Q2341.31 1521.12 2341.31 1529.87 Q2341.31 1538.6 2338.23 1543.21 Q2335.18 1547.79 2329.37 1547.79 Q2323.56 1547.79 2320.48 1543.21 Q2317.42 1538.6 2317.42 1529.87 Q2317.42 1521.12 2320.48 1516.54 Q2323.56 1511.93 2329.37 1511.93 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip972)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  231.181,1473.58 2352.76,1473.58 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip972)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  231.181,1159.83 2352.76,1159.83 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip972)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  231.181,846.069 2352.76,846.069 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip972)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  231.181,532.313 2352.76,532.313 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip972)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  231.181,218.556 2352.76,218.556 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  231.181,1486.45 231.181,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  231.181,1473.58 250.079,1473.58 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  231.181,1159.83 250.079,1159.83 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  231.181,846.069 250.079,846.069 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  231.181,532.313 250.079,532.313 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  231.181,218.556 250.079,218.556 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip970)\" d=\"M53.3995 1486.93 L61.0384 1486.93 L61.0384 1460.56 L52.7282 1462.23 L52.7282 1457.97 L60.9921 1456.3 L65.668 1456.3 L65.668 1486.93 L73.3068 1486.93 L73.3068 1490.86 L53.3995 1490.86 L53.3995 1486.93 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M92.7512 1459.38 Q89.1401 1459.38 87.3114 1462.94 Q85.5058 1466.49 85.5058 1473.62 Q85.5058 1480.72 87.3114 1484.29 Q89.1401 1487.83 92.7512 1487.83 Q96.3854 1487.83 98.1909 1484.29 Q100.02 1480.72 100.02 1473.62 Q100.02 1466.49 98.1909 1462.94 Q96.3854 1459.38 92.7512 1459.38 M92.7512 1455.68 Q98.5613 1455.68 101.617 1460.28 Q104.696 1464.87 104.696 1473.62 Q104.696 1482.34 101.617 1486.95 Q98.5613 1491.53 92.7512 1491.53 Q86.941 1491.53 83.8623 1486.95 Q80.8068 1482.34 80.8068 1473.62 Q80.8068 1464.87 83.8623 1460.28 Q86.941 1455.68 92.7512 1455.68 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M122.913 1459.38 Q119.302 1459.38 117.473 1462.94 Q115.668 1466.49 115.668 1473.62 Q115.668 1480.72 117.473 1484.29 Q119.302 1487.83 122.913 1487.83 Q126.547 1487.83 128.353 1484.29 Q130.182 1480.72 130.182 1473.62 Q130.182 1466.49 128.353 1462.94 Q126.547 1459.38 122.913 1459.38 M122.913 1455.68 Q128.723 1455.68 131.779 1460.28 Q134.857 1464.87 134.857 1473.62 Q134.857 1482.34 131.779 1486.95 Q128.723 1491.53 122.913 1491.53 Q117.103 1491.53 114.024 1486.95 Q110.969 1482.34 110.969 1473.62 Q110.969 1464.87 114.024 1460.28 Q117.103 1455.68 122.913 1455.68 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M153.075 1459.38 Q149.464 1459.38 147.635 1462.94 Q145.83 1466.49 145.83 1473.62 Q145.83 1480.72 147.635 1484.29 Q149.464 1487.83 153.075 1487.83 Q156.709 1487.83 158.515 1484.29 Q160.343 1480.72 160.343 1473.62 Q160.343 1466.49 158.515 1462.94 Q156.709 1459.38 153.075 1459.38 M153.075 1455.68 Q158.885 1455.68 161.941 1460.28 Q165.019 1464.87 165.019 1473.62 Q165.019 1482.34 161.941 1486.95 Q158.885 1491.53 153.075 1491.53 Q147.265 1491.53 144.186 1486.95 Q141.131 1482.34 141.131 1473.62 Q141.131 1464.87 144.186 1460.28 Q147.265 1455.68 153.075 1455.68 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M183.237 1459.38 Q179.626 1459.38 177.797 1462.94 Q175.991 1466.49 175.991 1473.62 Q175.991 1480.72 177.797 1484.29 Q179.626 1487.83 183.237 1487.83 Q186.871 1487.83 188.677 1484.29 Q190.505 1480.72 190.505 1473.62 Q190.505 1466.49 188.677 1462.94 Q186.871 1459.38 183.237 1459.38 M183.237 1455.68 Q189.047 1455.68 192.102 1460.28 Q195.181 1464.87 195.181 1473.62 Q195.181 1482.34 192.102 1486.95 Q189.047 1491.53 183.237 1491.53 Q177.427 1491.53 174.348 1486.95 Q171.292 1482.34 171.292 1473.62 Q171.292 1464.87 174.348 1460.28 Q177.427 1455.68 183.237 1455.68 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M53.3995 1173.17 L61.0384 1173.17 L61.0384 1146.8 L52.7282 1148.47 L52.7282 1144.21 L60.9921 1142.55 L65.668 1142.55 L65.668 1173.17 L73.3068 1173.17 L73.3068 1177.11 L53.3995 1177.11 L53.3995 1173.17 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M86.779 1173.17 L103.098 1173.17 L103.098 1177.11 L81.154 1177.11 L81.154 1173.17 Q83.816 1170.42 88.3993 1165.79 Q93.0058 1161.13 94.1863 1159.79 Q96.4317 1157.27 97.3113 1155.53 Q98.2141 1153.77 98.2141 1152.08 Q98.2141 1149.33 96.2697 1147.59 Q94.3484 1145.86 91.2465 1145.86 Q89.0475 1145.86 86.5938 1146.62 Q84.1632 1147.38 81.3855 1148.93 L81.3855 1144.21 Q84.2095 1143.08 86.6632 1142.5 Q89.1169 1141.92 91.1539 1141.92 Q96.5243 1141.92 99.7187 1144.61 Q102.913 1147.29 102.913 1151.78 Q102.913 1153.91 102.103 1155.83 Q101.316 1157.73 99.2095 1160.32 Q98.6308 1160.99 95.5289 1164.21 Q92.4271 1167.41 86.779 1173.17 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M112.959 1142.55 L131.316 1142.55 L131.316 1146.48 L117.242 1146.48 L117.242 1154.95 Q118.26 1154.61 119.279 1154.44 Q120.297 1154.26 121.316 1154.26 Q127.103 1154.26 130.482 1157.43 Q133.862 1160.6 133.862 1166.02 Q133.862 1171.6 130.39 1174.7 Q126.918 1177.78 120.598 1177.78 Q118.422 1177.78 116.154 1177.41 Q113.908 1177.04 111.501 1176.29 L111.501 1171.6 Q113.584 1172.73 115.807 1173.29 Q118.029 1173.84 120.506 1173.84 Q124.51 1173.84 126.848 1171.73 Q129.186 1169.63 129.186 1166.02 Q129.186 1162.41 126.848 1160.3 Q124.51 1158.19 120.506 1158.19 Q118.631 1158.19 116.756 1158.61 Q114.904 1159.03 112.959 1159.91 L112.959 1142.55 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M153.075 1145.62 Q149.464 1145.62 147.635 1149.19 Q145.83 1152.73 145.83 1159.86 Q145.83 1166.97 147.635 1170.53 Q149.464 1174.07 153.075 1174.07 Q156.709 1174.07 158.515 1170.53 Q160.343 1166.97 160.343 1159.86 Q160.343 1152.73 158.515 1149.19 Q156.709 1145.62 153.075 1145.62 M153.075 1141.92 Q158.885 1141.92 161.941 1146.53 Q165.019 1151.11 165.019 1159.86 Q165.019 1168.59 161.941 1173.19 Q158.885 1177.78 153.075 1177.78 Q147.265 1177.78 144.186 1173.19 Q141.131 1168.59 141.131 1159.86 Q141.131 1151.11 144.186 1146.53 Q147.265 1141.92 153.075 1141.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M183.237 1145.62 Q179.626 1145.62 177.797 1149.19 Q175.991 1152.73 175.991 1159.86 Q175.991 1166.97 177.797 1170.53 Q179.626 1174.07 183.237 1174.07 Q186.871 1174.07 188.677 1170.53 Q190.505 1166.97 190.505 1159.86 Q190.505 1152.73 188.677 1149.19 Q186.871 1145.62 183.237 1145.62 M183.237 1141.92 Q189.047 1141.92 192.102 1146.53 Q195.181 1151.11 195.181 1159.86 Q195.181 1168.59 192.102 1173.19 Q189.047 1177.78 183.237 1177.78 Q177.427 1177.78 174.348 1173.19 Q171.292 1168.59 171.292 1159.86 Q171.292 1151.11 174.348 1146.53 Q177.427 1141.92 183.237 1141.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M53.3995 859.414 L61.0384 859.414 L61.0384 833.048 L52.7282 834.715 L52.7282 830.455 L60.9921 828.789 L65.668 828.789 L65.668 859.414 L73.3068 859.414 L73.3068 863.349 L53.3995 863.349 L53.3995 859.414 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M82.7975 828.789 L101.154 828.789 L101.154 832.724 L87.0799 832.724 L87.0799 841.196 Q88.0984 840.849 89.1169 840.687 Q90.1354 840.502 91.1539 840.502 Q96.941 840.502 100.321 843.673 Q103.7 846.844 103.7 852.261 Q103.7 857.84 100.228 860.941 Q96.7558 864.02 90.4364 864.02 Q88.2604 864.02 85.9919 863.65 Q83.7466 863.279 81.3392 862.539 L81.3392 857.84 Q83.4225 858.974 85.6447 859.529 Q87.8669 860.085 90.3438 860.085 Q94.3484 860.085 96.6863 857.978 Q99.0243 855.872 99.0243 852.261 Q99.0243 848.65 96.6863 846.543 Q94.3484 844.437 90.3438 844.437 Q88.4688 844.437 86.5938 844.854 Q84.7419 845.27 82.7975 846.15 L82.7975 828.789 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M122.913 831.867 Q119.302 831.867 117.473 835.432 Q115.668 838.974 115.668 846.104 Q115.668 853.21 117.473 856.775 Q119.302 860.316 122.913 860.316 Q126.547 860.316 128.353 856.775 Q130.182 853.21 130.182 846.104 Q130.182 838.974 128.353 835.432 Q126.547 831.867 122.913 831.867 M122.913 828.164 Q128.723 828.164 131.779 832.77 Q134.857 837.354 134.857 846.104 Q134.857 854.83 131.779 859.437 Q128.723 864.02 122.913 864.02 Q117.103 864.02 114.024 859.437 Q110.969 854.83 110.969 846.104 Q110.969 837.354 114.024 832.77 Q117.103 828.164 122.913 828.164 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M153.075 831.867 Q149.464 831.867 147.635 835.432 Q145.83 838.974 145.83 846.104 Q145.83 853.21 147.635 856.775 Q149.464 860.316 153.075 860.316 Q156.709 860.316 158.515 856.775 Q160.343 853.21 160.343 846.104 Q160.343 838.974 158.515 835.432 Q156.709 831.867 153.075 831.867 M153.075 828.164 Q158.885 828.164 161.941 832.77 Q165.019 837.354 165.019 846.104 Q165.019 854.83 161.941 859.437 Q158.885 864.02 153.075 864.02 Q147.265 864.02 144.186 859.437 Q141.131 854.83 141.131 846.104 Q141.131 837.354 144.186 832.77 Q147.265 828.164 153.075 828.164 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M183.237 831.867 Q179.626 831.867 177.797 835.432 Q175.991 838.974 175.991 846.104 Q175.991 853.21 177.797 856.775 Q179.626 860.316 183.237 860.316 Q186.871 860.316 188.677 856.775 Q190.505 853.21 190.505 846.104 Q190.505 838.974 188.677 835.432 Q186.871 831.867 183.237 831.867 M183.237 828.164 Q189.047 828.164 192.102 832.77 Q195.181 837.354 195.181 846.104 Q195.181 854.83 192.102 859.437 Q189.047 864.02 183.237 864.02 Q177.427 864.02 174.348 859.437 Q171.292 854.83 171.292 846.104 Q171.292 837.354 174.348 832.77 Q177.427 828.164 183.237 828.164 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M53.3995 545.657 L61.0384 545.657 L61.0384 519.292 L52.7282 520.958 L52.7282 516.699 L60.9921 515.033 L65.668 515.033 L65.668 545.657 L73.3068 545.657 L73.3068 549.593 L53.3995 549.593 L53.3995 545.657 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M81.5707 515.033 L103.793 515.033 L103.793 517.023 L91.2465 549.593 L86.3623 549.593 L98.1678 518.968 L81.5707 518.968 L81.5707 515.033 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M112.959 515.033 L131.316 515.033 L131.316 518.968 L117.242 518.968 L117.242 527.44 Q118.26 527.093 119.279 526.931 Q120.297 526.745 121.316 526.745 Q127.103 526.745 130.482 529.917 Q133.862 533.088 133.862 538.505 Q133.862 544.083 130.39 547.185 Q126.918 550.264 120.598 550.264 Q118.422 550.264 116.154 549.894 Q113.908 549.523 111.501 548.782 L111.501 544.083 Q113.584 545.218 115.807 545.773 Q118.029 546.329 120.506 546.329 Q124.51 546.329 126.848 544.222 Q129.186 542.116 129.186 538.505 Q129.186 534.894 126.848 532.787 Q124.51 530.681 120.506 530.681 Q118.631 530.681 116.756 531.097 Q114.904 531.514 112.959 532.394 L112.959 515.033 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M153.075 518.111 Q149.464 518.111 147.635 521.676 Q145.83 525.218 145.83 532.347 Q145.83 539.454 147.635 543.019 Q149.464 546.56 153.075 546.56 Q156.709 546.56 158.515 543.019 Q160.343 539.454 160.343 532.347 Q160.343 525.218 158.515 521.676 Q156.709 518.111 153.075 518.111 M153.075 514.408 Q158.885 514.408 161.941 519.014 Q165.019 523.597 165.019 532.347 Q165.019 541.074 161.941 545.681 Q158.885 550.264 153.075 550.264 Q147.265 550.264 144.186 545.681 Q141.131 541.074 141.131 532.347 Q141.131 523.597 144.186 519.014 Q147.265 514.408 153.075 514.408 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M183.237 518.111 Q179.626 518.111 177.797 521.676 Q175.991 525.218 175.991 532.347 Q175.991 539.454 177.797 543.019 Q179.626 546.56 183.237 546.56 Q186.871 546.56 188.677 543.019 Q190.505 539.454 190.505 532.347 Q190.505 525.218 188.677 521.676 Q186.871 518.111 183.237 518.111 M183.237 514.408 Q189.047 514.408 192.102 519.014 Q195.181 523.597 195.181 532.347 Q195.181 541.074 192.102 545.681 Q189.047 550.264 183.237 550.264 Q177.427 550.264 174.348 545.681 Q171.292 541.074 171.292 532.347 Q171.292 523.597 174.348 519.014 Q177.427 514.408 183.237 514.408 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M56.6171 231.901 L72.9365 231.901 L72.9365 235.836 L50.9921 235.836 L50.9921 231.901 Q53.6541 229.147 58.2375 224.517 Q62.8439 219.864 64.0245 218.522 Q66.2698 215.999 67.1494 214.262 Q68.0522 212.503 68.0522 210.813 Q68.0522 208.059 66.1078 206.323 Q64.1865 204.587 61.0847 204.587 Q58.8856 204.587 56.4319 205.35 Q54.0014 206.114 51.2236 207.665 L51.2236 202.943 Q54.0477 201.809 56.5014 201.23 Q58.955 200.651 60.9921 200.651 Q66.3624 200.651 69.5568 203.337 Q72.7513 206.022 72.7513 210.512 Q72.7513 212.642 71.9411 214.563 Q71.1541 216.461 69.0476 219.054 Q68.4689 219.725 65.367 222.943 Q62.2652 226.137 56.6171 231.901 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M92.7512 204.355 Q89.1401 204.355 87.3114 207.92 Q85.5058 211.461 85.5058 218.591 Q85.5058 225.698 87.3114 229.262 Q89.1401 232.804 92.7512 232.804 Q96.3854 232.804 98.1909 229.262 Q100.02 225.698 100.02 218.591 Q100.02 211.461 98.1909 207.92 Q96.3854 204.355 92.7512 204.355 M92.7512 200.651 Q98.5613 200.651 101.617 205.258 Q104.696 209.841 104.696 218.591 Q104.696 227.318 101.617 231.924 Q98.5613 236.508 92.7512 236.508 Q86.941 236.508 83.8623 231.924 Q80.8068 227.318 80.8068 218.591 Q80.8068 209.841 83.8623 205.258 Q86.941 200.651 92.7512 200.651 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M122.913 204.355 Q119.302 204.355 117.473 207.92 Q115.668 211.461 115.668 218.591 Q115.668 225.698 117.473 229.262 Q119.302 232.804 122.913 232.804 Q126.547 232.804 128.353 229.262 Q130.182 225.698 130.182 218.591 Q130.182 211.461 128.353 207.92 Q126.547 204.355 122.913 204.355 M122.913 200.651 Q128.723 200.651 131.779 205.258 Q134.857 209.841 134.857 218.591 Q134.857 227.318 131.779 231.924 Q128.723 236.508 122.913 236.508 Q117.103 236.508 114.024 231.924 Q110.969 227.318 110.969 218.591 Q110.969 209.841 114.024 205.258 Q117.103 200.651 122.913 200.651 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M153.075 204.355 Q149.464 204.355 147.635 207.92 Q145.83 211.461 145.83 218.591 Q145.83 225.698 147.635 229.262 Q149.464 232.804 153.075 232.804 Q156.709 232.804 158.515 229.262 Q160.343 225.698 160.343 218.591 Q160.343 211.461 158.515 207.92 Q156.709 204.355 153.075 204.355 M153.075 200.651 Q158.885 200.651 161.941 205.258 Q165.019 209.841 165.019 218.591 Q165.019 227.318 161.941 231.924 Q158.885 236.508 153.075 236.508 Q147.265 236.508 144.186 231.924 Q141.131 227.318 141.131 218.591 Q141.131 209.841 144.186 205.258 Q147.265 200.651 153.075 200.651 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M183.237 204.355 Q179.626 204.355 177.797 207.92 Q175.991 211.461 175.991 218.591 Q175.991 225.698 177.797 229.262 Q179.626 232.804 183.237 232.804 Q186.871 232.804 188.677 229.262 Q190.505 225.698 190.505 218.591 Q190.505 211.461 188.677 207.92 Q186.871 204.355 183.237 204.355 M183.237 200.651 Q189.047 200.651 192.102 205.258 Q195.181 209.841 195.181 218.591 Q195.181 227.318 192.102 231.924 Q189.047 236.508 183.237 236.508 Q177.427 236.508 174.348 231.924 Q171.292 227.318 171.292 218.591 Q171.292 209.841 174.348 205.258 Q177.427 200.651 183.237 200.651 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1047.05 72.576 L1023.96 12.096 L1032.51 12.096 L1051.67 63.0159 L1070.87 12.096 L1079.38 12.096 L1056.33 72.576 L1047.05 72.576 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1129.45 63.9476 L1129.45 47.7034 L1116.08 47.7034 L1116.08 40.9789 L1137.55 40.9789 L1137.55 66.9452 Q1132.81 70.3075 1127.1 72.0494 Q1121.38 73.7508 1114.9 73.7508 Q1100.73 73.7508 1092.7 65.4869 Q1084.72 57.1826 1084.72 42.3968 Q1084.72 27.5705 1092.7 19.3066 Q1100.73 11.0023 1114.9 11.0023 Q1120.82 11.0023 1126.12 12.4606 Q1131.47 13.9189 1135.97 16.7545 L1135.97 25.464 Q1131.43 21.6156 1126.33 19.6712 Q1121.22 17.7268 1115.59 17.7268 Q1104.49 17.7268 1098.9 23.9246 Q1093.35 30.1225 1093.35 42.3968 Q1093.35 54.6305 1098.9 60.8284 Q1104.49 67.0263 1115.59 67.0263 Q1119.93 67.0263 1123.33 66.2971 Q1126.73 65.5274 1129.45 63.9476 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1193.73 63.9476 L1193.73 47.7034 L1180.37 47.7034 L1180.37 40.9789 L1201.84 40.9789 L1201.84 66.9452 Q1197.1 70.3075 1191.38 72.0494 Q1185.67 73.7508 1179.19 73.7508 Q1165.01 73.7508 1156.99 65.4869 Q1149.01 57.1826 1149.01 42.3968 Q1149.01 27.5705 1156.99 19.3066 Q1165.01 11.0023 1179.19 11.0023 Q1185.11 11.0023 1190.41 12.4606 Q1195.76 13.9189 1200.26 16.7545 L1200.26 25.464 Q1195.72 21.6156 1190.61 19.6712 Q1185.51 17.7268 1179.88 17.7268 Q1168.78 17.7268 1163.19 23.9246 Q1157.64 30.1225 1157.64 42.3968 Q1157.64 54.6305 1163.19 60.8284 Q1168.78 67.0263 1179.88 67.0263 Q1184.21 67.0263 1187.62 66.2971 Q1191.02 65.5274 1193.73 63.9476 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1242.3 39.9662 Q1248.18 41.222 1251.46 45.1919 Q1254.78 49.1618 1254.78 54.9951 Q1254.78 63.9476 1248.62 68.8492 Q1242.47 73.7508 1231.12 73.7508 Q1227.32 73.7508 1223.27 72.9811 Q1219.25 72.2519 1214.96 70.7531 L1214.96 62.8538 Q1218.36 64.8388 1222.41 65.8515 Q1226.47 66.8642 1230.88 66.8642 Q1238.58 66.8642 1242.59 63.826 Q1246.64 60.7879 1246.64 54.9951 Q1246.64 49.6479 1242.87 46.6502 Q1239.14 43.612 1232.46 43.612 L1225.41 43.612 L1225.41 36.8875 L1232.78 36.8875 Q1238.82 36.8875 1242.02 34.4975 Q1245.22 32.067 1245.22 27.5299 Q1245.22 22.8714 1241.9 20.4004 Q1238.62 17.8888 1232.46 17.8888 Q1229.1 17.8888 1225.25 18.618 Q1221.4 19.3471 1216.78 20.8865 L1216.78 13.5948 Q1221.44 12.2985 1225.49 11.6504 Q1229.58 11.0023 1233.19 11.0023 Q1242.51 11.0023 1247.94 15.2557 Q1253.36 19.4686 1253.36 26.6793 Q1253.36 31.7024 1250.49 35.1862 Q1247.61 38.6294 1242.3 39.9662 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1295.94 12.096 L1304.12 12.096 L1304.12 65.6895 L1333.57 65.6895 L1333.57 72.576 L1295.94 72.576 L1295.94 12.096 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1357.96 32.4315 Q1351.96 32.4315 1348.48 37.1306 Q1344.99 41.7891 1344.99 49.9314 Q1344.99 58.0738 1348.44 62.7728 Q1351.92 67.4314 1357.96 67.4314 Q1363.91 67.4314 1367.4 62.7323 Q1370.88 58.0333 1370.88 49.9314 Q1370.88 41.8701 1367.4 37.1711 Q1363.91 32.4315 1357.96 32.4315 M1357.96 26.1121 Q1367.68 26.1121 1373.23 32.4315 Q1378.78 38.7509 1378.78 49.9314 Q1378.78 61.0714 1373.23 67.4314 Q1367.68 73.7508 1357.96 73.7508 Q1348.2 73.7508 1342.65 67.4314 Q1337.14 61.0714 1337.14 49.9314 Q1337.14 38.7509 1342.65 32.4315 Q1348.2 26.1121 1357.96 26.1121 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1420.06 28.5427 L1420.06 35.5912 Q1416.9 33.9709 1413.5 33.1607 Q1410.09 32.3505 1406.45 32.3505 Q1400.9 32.3505 1398.1 34.0519 Q1395.35 35.7533 1395.35 39.156 Q1395.35 41.7486 1397.33 43.2475 Q1399.32 44.7058 1405.31 46.0426 L1407.86 46.6097 Q1415.8 48.3111 1419.13 51.4303 Q1422.49 54.509 1422.49 60.0587 Q1422.49 66.3781 1417.47 70.0644 Q1412.48 73.7508 1403.73 73.7508 Q1400.09 73.7508 1396.12 73.0216 Q1392.19 72.3329 1387.81 70.9151 L1387.81 63.2184 Q1391.94 65.3654 1395.96 66.4591 Q1399.97 67.5124 1403.9 67.5124 Q1409.16 67.5124 1412 65.73 Q1414.83 63.9071 1414.83 60.6258 Q1414.83 57.5877 1412.77 55.9673 Q1410.74 54.3469 1403.81 52.8481 L1401.22 52.2405 Q1394.29 50.7821 1391.22 47.7845 Q1388.14 44.7463 1388.14 39.4801 Q1388.14 33.0797 1392.67 29.5959 Q1397.21 26.1121 1405.56 26.1121 Q1409.69 26.1121 1413.33 26.7198 Q1416.98 27.3274 1420.06 28.5427 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1463.28 28.5427 L1463.28 35.5912 Q1460.12 33.9709 1456.72 33.1607 Q1453.32 32.3505 1449.67 32.3505 Q1444.12 32.3505 1441.33 34.0519 Q1438.57 35.7533 1438.57 39.156 Q1438.57 41.7486 1440.56 43.2475 Q1442.54 44.7058 1448.54 46.0426 L1451.09 46.6097 Q1459.03 48.3111 1462.35 51.4303 Q1465.71 54.509 1465.71 60.0587 Q1465.71 66.3781 1460.69 70.0644 Q1455.71 73.7508 1446.96 73.7508 Q1443.31 73.7508 1439.34 73.0216 Q1435.41 72.3329 1431.04 70.9151 L1431.04 63.2184 Q1435.17 65.3654 1439.18 66.4591 Q1443.19 67.5124 1447.12 67.5124 Q1452.38 67.5124 1455.22 65.73 Q1458.06 63.9071 1458.06 60.6258 Q1458.06 57.5877 1455.99 55.9673 Q1453.96 54.3469 1447.04 52.8481 L1444.44 52.2405 Q1437.52 50.7821 1434.44 47.7845 Q1431.36 44.7463 1431.36 39.4801 Q1431.36 33.0797 1435.9 29.5959 Q1440.43 26.1121 1448.78 26.1121 Q1452.91 26.1121 1456.56 26.7198 Q1460.2 27.3274 1463.28 28.5427 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1516.39 48.0275 L1516.39 51.6733 L1482.12 51.6733 Q1482.6 59.3701 1486.74 63.421 Q1490.91 67.4314 1498.32 67.4314 Q1502.62 67.4314 1506.63 66.3781 Q1510.68 65.3249 1514.65 63.2184 L1514.65 70.267 Q1510.64 71.9684 1506.42 72.8596 Q1502.21 73.7508 1497.88 73.7508 Q1487.02 73.7508 1480.66 67.4314 Q1474.34 61.1119 1474.34 50.3365 Q1474.34 39.1965 1480.34 32.6746 Q1486.37 26.1121 1496.58 26.1121 Q1505.73 26.1121 1511.04 32.0264 Q1516.39 37.9003 1516.39 48.0275 M1508.93 45.84 Q1508.85 39.7232 1505.49 36.0774 Q1502.17 32.4315 1496.66 32.4315 Q1490.42 32.4315 1486.65 35.9558 Q1482.93 39.4801 1482.36 45.8805 L1508.93 45.84 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1557.55 28.5427 L1557.55 35.5912 Q1554.39 33.9709 1550.98 33.1607 Q1547.58 32.3505 1543.93 32.3505 Q1538.39 32.3505 1535.59 34.0519 Q1532.84 35.7533 1532.84 39.156 Q1532.84 41.7486 1534.82 43.2475 Q1536.81 44.7058 1542.8 46.0426 L1545.35 46.6097 Q1553.29 48.3111 1556.61 51.4303 Q1559.98 54.509 1559.98 60.0587 Q1559.98 66.3781 1554.95 70.0644 Q1549.97 73.7508 1541.22 73.7508 Q1537.57 73.7508 1533.6 73.0216 Q1529.68 72.3329 1525.3 70.9151 L1525.3 63.2184 Q1529.43 65.3654 1533.44 66.4591 Q1537.45 67.5124 1541.38 67.5124 Q1546.65 67.5124 1549.48 65.73 Q1552.32 63.9071 1552.32 60.6258 Q1552.32 57.5877 1550.25 55.9673 Q1548.23 54.3469 1541.3 52.8481 L1538.71 52.2405 Q1531.78 50.7821 1528.7 47.7845 Q1525.62 44.7463 1525.62 39.4801 Q1525.62 33.0797 1530.16 29.5959 Q1534.7 26.1121 1543.04 26.1121 Q1547.18 26.1121 1550.82 26.7198 Q1554.47 27.3274 1557.55 28.5427 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip972)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  291.226,172.421 513.613,442.557 736,734.265 958.388,834.346 1180.77,863.633 1403.16,1050.7 1625.55,1140.19 1847.94,1223.05 2070.32,1235.69 2292.71,1447.87 \n",
       "  \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip972)\" style=\"stroke:#e26f46; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  291.226,162.047 513.613,430.683 736,715.953 958.388,785.255 1180.77,811.926 1403.16,961.001 1625.55,1026.85 1847.94,1063.25 2070.32,1054.35 2292.71,1220.1 \n",
       "  \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip970)\" d=\"\n",
       "M1815.68 324.425 L2282.04 324.425 L2282.04 168.905 L1815.68 168.905  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1815.68,324.425 2282.04,324.425 2282.04,168.905 1815.68,168.905 1815.68,324.425 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip970)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1839.26,220.745 1980.69,220.745 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip970)\" d=\"M2004.27 203.465 L2033.5 203.465 L2033.5 207.4 L2021.23 207.4 L2021.23 238.025 L2016.54 238.025 L2016.54 207.4 L2004.27 207.4 L2004.27 203.465 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M2045.89 216.08 Q2045.17 215.664 2044.31 215.478 Q2043.48 215.27 2042.46 215.27 Q2038.85 215.27 2036.91 217.631 Q2034.98 219.969 2034.98 224.367 L2034.98 238.025 L2030.7 238.025 L2030.7 212.099 L2034.98 212.099 L2034.98 216.127 Q2036.33 213.766 2038.48 212.631 Q2040.63 211.474 2043.71 211.474 Q2044.15 211.474 2044.68 211.543 Q2045.22 211.59 2045.86 211.705 L2045.89 216.08 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M2062.14 224.992 Q2056.97 224.992 2054.98 226.173 Q2052.99 227.353 2052.99 230.201 Q2052.99 232.469 2054.47 233.812 Q2055.98 235.131 2058.55 235.131 Q2062.09 235.131 2064.22 232.631 Q2066.37 230.108 2066.37 225.941 L2066.37 224.992 L2062.14 224.992 M2070.63 223.233 L2070.63 238.025 L2066.37 238.025 L2066.37 234.089 Q2064.91 236.451 2062.74 237.585 Q2060.56 238.696 2057.41 238.696 Q2053.43 238.696 2051.07 236.474 Q2048.73 234.228 2048.73 230.478 Q2048.73 226.103 2051.65 223.881 Q2054.59 221.659 2060.4 221.659 L2066.37 221.659 L2066.37 221.242 Q2066.37 218.303 2064.43 216.705 Q2062.51 215.085 2059.01 215.085 Q2056.79 215.085 2054.68 215.617 Q2052.58 216.15 2050.63 217.215 L2050.63 213.279 Q2052.97 212.377 2055.17 211.937 Q2057.37 211.474 2059.45 211.474 Q2065.08 211.474 2067.85 214.391 Q2070.63 217.307 2070.63 223.233 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M2079.41 212.099 L2083.66 212.099 L2083.66 238.025 L2079.41 238.025 L2079.41 212.099 M2079.41 202.006 L2083.66 202.006 L2083.66 207.4 L2079.41 207.4 L2079.41 202.006 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M2114.13 222.377 L2114.13 238.025 L2109.87 238.025 L2109.87 222.515 Q2109.87 218.835 2108.43 217.006 Q2107 215.178 2104.13 215.178 Q2100.68 215.178 2098.69 217.377 Q2096.7 219.576 2096.7 223.372 L2096.7 238.025 L2092.41 238.025 L2092.41 212.099 L2096.7 212.099 L2096.7 216.127 Q2098.22 213.789 2100.28 212.631 Q2102.37 211.474 2105.08 211.474 Q2109.54 211.474 2111.84 214.252 Q2114.13 217.006 2114.13 222.377 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M2137.88 203.465 L2142.55 203.465 L2142.55 234.089 L2159.38 234.089 L2159.38 238.025 L2137.88 238.025 L2137.88 203.465 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M2173.32 215.085 Q2169.89 215.085 2167.9 217.77 Q2165.91 220.432 2165.91 225.085 Q2165.91 229.738 2167.88 232.423 Q2169.87 235.085 2173.32 235.085 Q2176.72 235.085 2178.71 232.4 Q2180.7 229.715 2180.7 225.085 Q2180.7 220.478 2178.71 217.793 Q2176.72 215.085 2173.32 215.085 M2173.32 211.474 Q2178.87 211.474 2182.04 215.085 Q2185.21 218.696 2185.21 225.085 Q2185.21 231.451 2182.04 235.085 Q2178.87 238.696 2173.32 238.696 Q2167.74 238.696 2164.57 235.085 Q2161.42 231.451 2161.42 225.085 Q2161.42 218.696 2164.57 215.085 Q2167.74 211.474 2173.32 211.474 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M2208.8 212.863 L2208.8 216.891 Q2207 215.965 2205.05 215.502 Q2203.11 215.039 2201.03 215.039 Q2197.85 215.039 2196.26 216.011 Q2194.68 216.983 2194.68 218.928 Q2194.68 220.409 2195.82 221.265 Q2196.95 222.099 2200.38 222.863 L2201.84 223.187 Q2206.37 224.159 2208.27 225.941 Q2210.19 227.701 2210.19 230.872 Q2210.19 234.483 2207.32 236.589 Q2204.47 238.696 2199.47 238.696 Q2197.39 238.696 2195.12 238.279 Q2192.88 237.886 2190.38 237.076 L2190.38 232.677 Q2192.74 233.904 2195.03 234.529 Q2197.32 235.131 2199.57 235.131 Q2202.58 235.131 2204.2 234.113 Q2205.82 233.071 2205.82 231.196 Q2205.82 229.46 2204.64 228.534 Q2203.48 227.608 2199.52 226.752 L2198.04 226.404 Q2194.08 225.571 2192.32 223.858 Q2190.56 222.122 2190.56 219.113 Q2190.56 215.455 2193.15 213.465 Q2195.75 211.474 2200.52 211.474 Q2202.88 211.474 2204.96 211.821 Q2207.04 212.168 2208.8 212.863 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M2233.5 212.863 L2233.5 216.891 Q2231.7 215.965 2229.75 215.502 Q2227.81 215.039 2225.72 215.039 Q2222.55 215.039 2220.96 216.011 Q2219.38 216.983 2219.38 218.928 Q2219.38 220.409 2220.52 221.265 Q2221.65 222.099 2225.08 222.863 L2226.53 223.187 Q2231.07 224.159 2232.97 225.941 Q2234.89 227.701 2234.89 230.872 Q2234.89 234.483 2232.02 236.589 Q2229.17 238.696 2224.17 238.696 Q2222.09 238.696 2219.82 238.279 Q2217.58 237.886 2215.08 237.076 L2215.08 232.677 Q2217.44 233.904 2219.73 234.529 Q2222.02 235.131 2224.27 235.131 Q2227.27 235.131 2228.9 234.113 Q2230.52 233.071 2230.52 231.196 Q2230.52 229.46 2229.34 228.534 Q2228.18 227.608 2224.22 226.752 L2222.74 226.404 Q2218.78 225.571 2217.02 223.858 Q2215.26 222.122 2215.26 219.113 Q2215.26 215.455 2217.85 213.465 Q2220.45 211.474 2225.21 211.474 Q2227.58 211.474 2229.66 211.821 Q2231.74 212.168 2233.5 212.863 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip970)\" style=\"stroke:#e26f46; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1839.26,272.585 1980.69,272.585 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip970)\" d=\"M2004.27 255.305 L2033.5 255.305 L2033.5 259.24 L2021.23 259.24 L2021.23 289.865 L2016.54 289.865 L2016.54 259.24 L2004.27 259.24 L2004.27 255.305 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M2051.95 275.837 L2051.95 277.92 L2032.37 277.92 Q2032.65 282.318 2035.01 284.633 Q2037.39 286.925 2041.63 286.925 Q2044.08 286.925 2046.37 286.323 Q2048.69 285.721 2050.96 284.517 L2050.96 288.545 Q2048.66 289.517 2046.26 290.027 Q2043.85 290.536 2041.37 290.536 Q2035.17 290.536 2031.54 286.925 Q2027.92 283.314 2027.92 277.156 Q2027.92 270.791 2031.35 267.064 Q2034.8 263.314 2040.63 263.314 Q2045.86 263.314 2048.9 266.693 Q2051.95 270.05 2051.95 275.837 M2047.69 274.587 Q2047.65 271.092 2045.72 269.008 Q2043.83 266.925 2040.68 266.925 Q2037.11 266.925 2034.96 268.939 Q2032.83 270.953 2032.51 274.61 L2047.69 274.587 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M2075.47 264.703 L2075.47 268.731 Q2073.66 267.805 2071.72 267.342 Q2069.78 266.879 2067.69 266.879 Q2064.52 266.879 2062.92 267.851 Q2061.35 268.823 2061.35 270.768 Q2061.35 272.249 2062.48 273.105 Q2063.62 273.939 2067.04 274.703 L2068.5 275.027 Q2073.04 275.999 2074.94 277.781 Q2076.86 279.541 2076.86 282.712 Q2076.86 286.323 2073.99 288.429 Q2071.14 290.536 2066.14 290.536 Q2064.06 290.536 2061.79 290.119 Q2059.54 289.726 2057.04 288.916 L2057.04 284.517 Q2059.41 285.744 2061.7 286.369 Q2063.99 286.971 2066.23 286.971 Q2069.24 286.971 2070.86 285.953 Q2072.48 284.911 2072.48 283.036 Q2072.48 281.3 2071.3 280.374 Q2070.15 279.448 2066.19 278.592 L2064.71 278.244 Q2060.75 277.411 2058.99 275.698 Q2057.23 273.962 2057.23 270.953 Q2057.23 267.295 2059.82 265.305 Q2062.41 263.314 2067.18 263.314 Q2069.54 263.314 2071.63 263.661 Q2073.71 264.008 2075.47 264.703 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M2087.85 256.578 L2087.85 263.939 L2096.63 263.939 L2096.63 267.249 L2087.85 267.249 L2087.85 281.323 Q2087.85 284.494 2088.71 285.397 Q2089.59 286.3 2092.25 286.3 L2096.63 286.3 L2096.63 289.865 L2092.25 289.865 Q2087.32 289.865 2085.45 288.036 Q2083.57 286.184 2083.57 281.323 L2083.57 267.249 L2080.45 267.249 L2080.45 263.939 L2083.57 263.939 L2083.57 256.578 L2087.85 256.578 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M2117.48 255.305 L2122.16 255.305 L2122.16 285.929 L2138.99 285.929 L2138.99 289.865 L2117.48 289.865 L2117.48 255.305 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M2152.92 266.925 Q2149.5 266.925 2147.51 269.61 Q2145.52 272.272 2145.52 276.925 Q2145.52 281.578 2147.48 284.263 Q2149.47 286.925 2152.92 286.925 Q2156.33 286.925 2158.32 284.24 Q2160.31 281.555 2160.31 276.925 Q2160.31 272.318 2158.32 269.633 Q2156.33 266.925 2152.92 266.925 M2152.92 263.314 Q2158.48 263.314 2161.65 266.925 Q2164.82 270.536 2164.82 276.925 Q2164.82 283.291 2161.65 286.925 Q2158.48 290.536 2152.92 290.536 Q2147.34 290.536 2144.17 286.925 Q2141.03 283.291 2141.03 276.925 Q2141.03 270.536 2144.17 266.925 Q2147.34 263.314 2152.92 263.314 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M2188.41 264.703 L2188.41 268.731 Q2186.6 267.805 2184.66 267.342 Q2182.71 266.879 2180.63 266.879 Q2177.46 266.879 2175.86 267.851 Q2174.29 268.823 2174.29 270.768 Q2174.29 272.249 2175.42 273.105 Q2176.56 273.939 2179.98 274.703 L2181.44 275.027 Q2185.98 275.999 2187.88 277.781 Q2189.8 279.541 2189.8 282.712 Q2189.8 286.323 2186.93 288.429 Q2184.08 290.536 2179.08 290.536 Q2177 290.536 2174.73 290.119 Q2172.48 289.726 2169.98 288.916 L2169.98 284.517 Q2172.34 285.744 2174.64 286.369 Q2176.93 286.971 2179.17 286.971 Q2182.18 286.971 2183.8 285.953 Q2185.42 284.911 2185.42 283.036 Q2185.42 281.3 2184.24 280.374 Q2183.09 279.448 2179.13 278.592 L2177.65 278.244 Q2173.69 277.411 2171.93 275.698 Q2170.17 273.962 2170.17 270.953 Q2170.17 267.295 2172.76 265.305 Q2175.35 263.314 2180.12 263.314 Q2182.48 263.314 2184.57 263.661 Q2186.65 264.008 2188.41 264.703 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M2213.11 264.703 L2213.11 268.731 Q2211.3 267.805 2209.36 267.342 Q2207.41 266.879 2205.33 266.879 Q2202.16 266.879 2200.56 267.851 Q2198.99 268.823 2198.99 270.768 Q2198.99 272.249 2200.12 273.105 Q2201.26 273.939 2204.68 274.703 L2206.14 275.027 Q2210.68 275.999 2212.58 277.781 Q2214.5 279.541 2214.5 282.712 Q2214.5 286.323 2211.63 288.429 Q2208.78 290.536 2203.78 290.536 Q2201.7 290.536 2199.43 290.119 Q2197.18 289.726 2194.68 288.916 L2194.68 284.517 Q2197.04 285.744 2199.34 286.369 Q2201.63 286.971 2203.87 286.971 Q2206.88 286.971 2208.5 285.953 Q2210.12 284.911 2210.12 283.036 Q2210.12 281.3 2208.94 280.374 Q2207.78 279.448 2203.83 278.592 L2202.34 278.244 Q2198.39 277.411 2196.63 275.698 Q2194.87 273.962 2194.87 270.953 Q2194.87 267.295 2197.46 265.305 Q2200.05 263.314 2204.82 263.314 Q2207.18 263.314 2209.27 263.661 Q2211.35 264.008 2213.11 264.703 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "plot(range(0, 10,length =10),vgg3_train_loss, labels=\"Train Loss\")\n",
    "plot!(range(0, 10,length =10),vgg3_test_loss, labels=\"Test Loss\", title=\"VGG3 Losses\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Conv((6, 6), 3 => 45, relu, pad=(3, 2, 3, 2)),  \u001b[90m# 4_905 parameters\u001b[39m\n",
       "  Conv((9, 9), 45 => 84, relu, pad=4),  \u001b[90m# 306_264 parameters\u001b[39m\n",
       "  MaxPool((2, 2)),\n",
       "  Dropout(0.2),\n",
       "  Conv((7, 7), 84 => 87, relu, pad=3),  \u001b[90m# 358_179 parameters\u001b[39m\n",
       "  Conv((4, 4), 87 => 92, relu, pad=(2, 1, 2, 1)),  \u001b[90m# 128_156 parameters\u001b[39m\n",
       "  MaxPool((2, 2)),\n",
       "  Dropout(0.2),\n",
       "  Conv((9, 9), 92 => 107, relu, pad=4),  \u001b[90m# 797_471 parameters\u001b[39m\n",
       "  Conv((7, 7), 107 => 167, relu, pad=3),  \u001b[90m# 875_748 parameters\u001b[39m\n",
       "  MaxPool((2, 2)),\n",
       "  Dropout(0.2),\n",
       "  Flux.flatten,\n",
       "  Dense(2672, 208, relu),               \u001b[90m# 555_984 parameters\u001b[39m\n",
       "  Dropout(0.2),\n",
       "  Dense(208, 10),                       \u001b[90m# 2_090 parameters\u001b[39m\n",
       "  NNlib.softmax,\n",
       ")\u001b[90m                   # Total: 16 arrays, \u001b[39m3_028_797 parameters, 11.557 MiB."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PSO optimized model, 10 iterations\n",
    "pso10_model = Chain(Conv((6,6), 3=>45, relu, pad=SamePad()),\n",
    "    Conv((9,9), 45=>84, relu, pad=SamePad()),\n",
    "    MaxPool((2,2)),\n",
    "    Dropout(0.2),\n",
    "    Conv((7,7), 84=>87, relu, pad=SamePad()),\n",
    "    Conv((4,4), 87=>92, relu, pad=SamePad()),\n",
    "    MaxPool((2,2)),\n",
    "    Dropout(0.2),\n",
    "    Conv((9,9), 92=>107, relu, pad=SamePad()),\n",
    "    Conv((7,7), 107=>167, relu, pad=SamePad()),\n",
    "    MaxPool((2,2)),\n",
    "    Dropout(0.2),\n",
    "    Flux.flatten,\n",
    "    Dense(2672,208,relu),\n",
    "    Dropout(0.2),\n",
    "    Dense(208,10),\n",
    "    softmax)\n",
    "#pso10_model(rand(Float32,32,32,3,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 for VGG3 architecture.\n",
      "  train_loss = 24162.203, train_accuracy = 0.11\n",
      "  test_loss = 24325.01, test_accuracy = 0.1053\n",
      "Epoch 2 for VGG3 architecture.\n",
      "  train_loss = 22783.695, train_accuracy = 0.1664\n",
      "  test_loss = 22865.137, test_accuracy = 0.1624\n",
      "Epoch 3 for VGG3 architecture.\n",
      "  train_loss = 20231.594, train_accuracy = 0.2448\n",
      "  test_loss = 20237.195, test_accuracy = 0.2431\n",
      "Epoch 4 for VGG3 architecture.\n",
      "  train_loss = 17211.207, train_accuracy = 0.3429\n",
      "  test_loss = 17416.523, test_accuracy = 0.3379\n",
      "Epoch 5 for VGG3 architecture.\n",
      "  train_loss = 17250.045, train_accuracy = 0.3417\n",
      "  test_loss = 17561.426, test_accuracy = 0.3361\n",
      "Epoch 6 for VGG3 architecture.\n",
      "  train_loss = 15933.777, train_accuracy = 0.3933\n",
      "  test_loss = 16501.467, test_accuracy = 0.3784\n",
      "Epoch 7 for VGG3 architecture.\n",
      "  train_loss = 14591.574, train_accuracy = 0.4534\n",
      "  test_loss = 15305.367, test_accuracy = 0.4351\n",
      "Epoch 8 for VGG3 architecture.\n",
      "  train_loss = 15003.525, train_accuracy = 0.4639\n",
      "  test_loss = 15784.356, test_accuracy = 0.4302\n",
      "Epoch 9 for VGG3 architecture.\n",
      "  train_loss = 14385.814, train_accuracy = 0.4626\n",
      "  test_loss = 15570.436, test_accuracy = 0.4211\n",
      "Epoch 10 for VGG3 architecture.\n",
      "  train_loss = 14696.279, train_accuracy = 0.4715\n",
      "  test_loss = 16099.835, test_accuracy = 0.4287\n"
     ]
    }
   ],
   "source": [
    "pso10_train_loss, \n",
    "pso10_train_accuracy, \n",
    "pso10_test_loss, \n",
    "pso10_test_accuracy = train(pso10_model,train_loader,train_x, train_y,test_x, test_y, \"PSO10\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "plot(range(0, 10,length =10),pso10_train_loss, labels=\"Train Loss\")\n",
    "plot!(range(0, 10,length =10),pso10_test_loss, labels=\"Test Loss\", title=\"PSO 10 Losses\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "CSE_598_Project_YZ_v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
