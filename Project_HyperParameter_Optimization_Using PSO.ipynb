{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38f4faa4",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization with PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aa9ba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using MLDatasets\n",
    "using Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8031904",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = CIFAR10.traindata(Float32, 1:50)\n",
    "test_x, test_y = CIFAR10.testdata(Float32, 1:50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d969fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y, test_y = Flux.onehotbatch(train_y, 0:9), Flux.onehotbatch(test_y, 0:9);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a831481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_and_accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss_and_accuracy(udata, wdata, model)\n",
    "    ndata = size(udata,4)\n",
    "    ŵ = model(udata)\n",
    "    loss = Flux.crossentropy(ŵ, wdata; agg=sum)\n",
    "    accuracy = sum(Flux.onecold(ŵ) .== Flux.onecold(wdata)) / ndata\n",
    "    return loss, accuracy\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e944163",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_loader = Flux.Data.DataLoader((train_x, train_y), batchsize=batch_size, shuffle=true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0752f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Particle \n",
    "    position::Vector{Int}\n",
    "    best_position::Vector{Int}\n",
    "    best_accuracy::Float32\n",
    "    velocity::Vector{Float32}\n",
    "    idx::Int\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6c633e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hyper_parameterized (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function hyper_parameterized(particle)\n",
    "    model_before_dense = Chain(\n",
    "              Conv((particle.position[1],particle.position[1]), 3=>particle.position[2], relu, pad=SamePad()),\n",
    "              Conv((particle.position[3],particle.position[3]), particle.position[2]=>particle.position[4], relu, pad=SamePad()),\n",
    "              MaxPool((particle.position[5],particle.position[5])),\n",
    "              Dropout(0.2),\n",
    "              Conv((particle.position[6],particle.position[6]), particle.position[4]=>particle.position[7], relu, pad=SamePad()),\n",
    "              Conv((particle.position[8],particle.position[8]), particle.position[7]=>particle.position[9], relu, pad=SamePad()),\n",
    "              MaxPool((particle.position[10],particle.position[10])),\n",
    "              Dropout(0.2),\n",
    "              Conv((particle.position[11],particle.position[11]), particle.position[9]=>particle.position[12], relu, pad=SamePad()),\n",
    "              Conv((particle.position[13],particle.position[13]), particle.position[12]=>particle.position[14], relu, pad=SamePad()),\n",
    "              MaxPool((2,2)),\n",
    "              Dropout(0.2),\n",
    "              Flux.flatten)\n",
    "    last_size = model_before_dense(rand(Float32, 32, 32, 3, 1)) |> size\n",
    "    return Chain(\n",
    "              Conv((particle.position[1],particle.position[1]), 3=>particle.position[2], relu, pad=SamePad()),\n",
    "              Conv((particle.position[3],particle.position[3]), particle.position[2]=>particle.position[4], relu, pad=SamePad()),\n",
    "              MaxPool((particle.position[5],particle.position[5])),\n",
    "              Dropout(0.2),\n",
    "              Conv((particle.position[6],particle.position[6]), particle.position[4]=>particle.position[7], relu, pad=SamePad()),\n",
    "              Conv((particle.position[8],particle.position[8]), particle.position[7]=>particle.position[9], relu, pad=SamePad()),\n",
    "              MaxPool((particle.position[10],particle.position[10])),\n",
    "              Dropout(0.2),\n",
    "              Conv((particle.position[11],particle.position[11]), particle.position[9]=>particle.position[12], relu, pad=SamePad()),\n",
    "              Conv((particle.position[13],particle.position[13]), particle.position[12]=>particle.position[14], relu, pad=SamePad()),\n",
    "              MaxPool((2,2)),\n",
    "              Dropout(0.2),\n",
    "              Flux.flatten,\n",
    "              Dense(last_size[1], particle.position[15], relu),\n",
    "              Dropout(0.2),\n",
    "              Dense(particle.position[15],10),\n",
    "              softmax)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5985281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train(model,train_loader,optimizer,train_x,train_y,test_x,test_y,model_name)\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    α = 0.001 # <- stepsize; in the ML community, it is often denoted as a `learning rate η`\n",
    "    #opt = optimizer(α) \n",
    "    opt = optimizer \n",
    "    K = 10\n",
    "    println(\"Training $model_name architecture.\")\n",
    "    for k in 1:K\n",
    "        for (u, w) in train_loader\n",
    "            gs = gradient(() -> Flux.Losses.crossentropy(model(u), w), Flux.params(model)) # compute gradient\n",
    "            Flux.Optimise.update!(opt, Flux.params(model), gs) # update parameters\n",
    "        end\n",
    "        test_loss, test_acc = loss_and_accuracy(test_x, test_y, model)\n",
    "\n",
    "        #println(\"  train_loss = $train_loss, train_accuracy = $train_acc\")\n",
    "        #println(\"  test_loss = $test_loss, test_accuracy = $test_acc\")\n",
    "    end\n",
    "    return test_loss, test_acc\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b174e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hyper_parameter_optimization (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function hyper_parameter_optimization(train_x, train_y, test_x, test_y, numparticles, ω, c1,c2)\n",
    "    lo = [2,1,2,1,2,2,1,2,1,2,2,2,2,2,10]\n",
    "    hi = [10,48,10,100,4,10,100,10,100,4,10,256,10,256,1000]\n",
    "    particles = []\n",
    "    best_accuracy = 0\n",
    "    swarm_best_position = []\n",
    "    # init particles - search space is 16 variables\n",
    "        #1   #2  #3   #4  #5   #6   #7  #8   #9  #10  #11  #12 #13 #14 #15\n",
    "    # [SF1, n1, SF2, n2, SP1, SF3, n3, SF4, n4, SP2, SF5, n5, SF6, n6, SD1]\n",
    "    for i in 1:numparticles\n",
    "        SF1 = rand(2:10)\n",
    "        n1 = rand(3:48)\n",
    "        SF2 = rand(2:10)\n",
    "        n2 = rand(n1:100)\n",
    "        SP1 = rand(2:4)\n",
    "        SF3 = rand(2:10)\n",
    "        n3 = rand(n2:100)\n",
    "        SF4 = rand(2:10)\n",
    "        n4 = rand(n3:100)\n",
    "        SP2 = rand(2:4)\n",
    "        SF5 = rand(2:10)\n",
    "        n5 = rand(n4:256)\n",
    "        SF6 = rand(2:10)\n",
    "        n6 = rand(n5:256)\n",
    "        SD1 = rand(10:1000)\n",
    "        push!(particles, Particle([SF1,n1,SF2,n2,SP1,SF3,n3,SF4,n4,SP2,SF5,n5,SF6,n6,SD1],\n",
    "                [SF1,n1,SF2,n2,SP1,SF3,n3,SF4,n4,SP2,SF5,n5,SF6,n6,SD1], 0, rand(Float32,15),i))\n",
    "    end\n",
    "    # find best model to work towards\n",
    "    for p in particles\n",
    "        m = hyper_parameterized(p)\n",
    "        this_acc = 0\n",
    "        for (u,w) in train_loader\n",
    "            this_loss, this_acc = loss_and_accuracy(train_x,train_y, m)\n",
    "        end\n",
    "        p.best_accuracy = this_acc\n",
    "        if p.best_accuracy > best_accuracy\n",
    "            best_accuracy = p.best_accuracy\n",
    "            swarm_best_position = p.position\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    println(\"Particles initalized\")\n",
    "    \n",
    "    for i in 1:100\n",
    "        for p in particles\n",
    "            # vector math for additional speed boost\n",
    "            # ω - inertia weight, how much the previous velocity impacts the current position\n",
    "            # c1 - how much the particle pays attention to its own best position\n",
    "            # c2 - how much the particle pays attention to the swarm's best position\n",
    "            r1 = rand((-1.0:1.0))\n",
    "            r2 = rand((-1.0:1.0))\n",
    "            p.velocity = (ω .* p.velocity) .+ r1 * c1 .* (p.best_position .- p.position) .+ r2 * c2 .* (swarm_best_position .- p.position)\n",
    "            p.position = clamp.(trunc.(Int, p.position + p.velocity),1,1000)\n",
    "            model = hyper_parameterized(p)\n",
    "            this_loss, this_acc = train(model,train_loader,ADAM(0.01),train_x,train_y,test_x,test_y,\"model $p.idx\")\n",
    "            println(\"Loss: $this_loss; Accuracy: $this_acc\")\n",
    "            \n",
    "            if p.best_accuracy < this_acc\n",
    "                p.best_accuracy = this_acc\n",
    "                p.best_position = p.position\n",
    "            end\n",
    "                \n",
    "            if best_accuracy < this_acc\n",
    "                \n",
    "                best_accuracy = this_acc\n",
    "                swarm_best_position = p.position\n",
    "                println(\"Changing accuracy to $best_accuracy\")\n",
    "            end\n",
    "            \n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return swarm_best_position\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c54a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particles initalized\n",
      "Training model Particle([5, 35, 4, 57, 3, 9, 88, 8, 97, 2, 4, 140, 5, 221, 850], [2, 36, 2, 50, 3, 9, 94, 8, 97, 3, 5, 118, 4, 224, 893], 0.08f0, Float32[3.322588, -0.17521325, 2.5703948, 7.243511, 0.88086027, 0.46931034, -5.1297398, 0.66945016, 0.89636767, -0.07103636, -0.40247476, 22.774555, 1.692674, -2.3450809, -42.96469], 1).idx architecture.\n",
      "Loss : 653.63776; Accuracy: 0.18\n",
      "Changing accuracy\n",
      "0.18\n",
      "Training model Particle([10, 35, 8, 68, 4, 9, 81, 9, 99, 2, 3, 174, 8, 217, 785], [10, 35, 8, 68, 4, 9, 81, 9, 99, 2, 3, 174, 8, 217, 785], 0.12f0, Float32[0.09185809, 0.23349273, 0.14723402, 0.15239114, 0.44463146, 0.18977511, 0.034646153, 0.15103954, 0.11905825, 0.454171, 0.38997853, 0.18910807, 0.43691856, 0.17298317, 0.28658605], 2).idx architecture.\n"
     ]
    }
   ],
   "source": [
    "b_p = hyper_parameter_optimization(train_x, train_y,test_x, test_y, 4, 0.5, 0.3, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07801bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
